{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test['label'] = 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = test.fillna(' ')\n",
    "train = train.fillna(' ')\n",
    "test['total'] = test['title'] + ' ' + test['author'] + test['text']\n",
    "train['total'] = train['title'] + ' ' + train['author'] + train['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "wl = WordNetLemmatizer()\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    # strip out punctuation and make lowercase\n",
    "    tokens = [token.lower().strip(string.punctuation)\n",
    "              for token in tokens if token.isalnum()]\n",
    "\n",
    "    # now stem the tokens\n",
    "    tokens = [wl.lemmatize(token) for token in tokens]\n",
    "    tokens = [word for word in tokens if len(word) >= 3 and word != ('said' or 'people')]\n",
    "    #tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 3), stop_words='english', tokenizer= tokenize_and_stem)\n",
    "counts = count_vectorizer.fit_transform(train['total'].values)\n",
    "tfidf = transformer.fit_transform(counts)\n",
    "targets = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiBayes\n",
      "Accuracy of NB classifier on training set: 0.97\n",
      "Accuracy of NB classifier on test set: 0.83\n",
      "Bernoulli\n",
      "Accuracy of NB classifier on training set: 0.93\n",
      "Accuracy of NB classifier on test set: 0.72\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf, targets, random_state=0)\n",
    "\n",
    "# multiBayes\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train, y_train)\n",
    "print(\"multiBayes\")\n",
    "print('Accuracy of NB classifier on training set: {:.2f}'\n",
    "      .format(NB.score(X_train, y_train)))\n",
    "print('Accuracy of NB classifier on test set: {:.2f}'\n",
    "      .format(NB.score(X_test, y_test)))\n",
    "\n",
    "BNB = BernoulliNB()\n",
    "BNB.fit(X_train, y_train)\n",
    "print(\"Bernoulli\")\n",
    "print('Accuracy of NB classifier on training set: {:.2f}'\n",
    "      .format(BNB.score(X_train, y_train)))\n",
    "print('Accuracy of NB classifier on test set: {:.2f}'\n",
    "      .format(BNB.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important words in real news articles\n",
      "0 59.329299871009006 breitbart\n",
      "0 52.19754111636912 york\n",
      "0 51.91481547074832 new york\n",
      "0 47.766852245074574 news\n",
      "0 47.128348756709165 republican\n",
      "0 46.28007769074222 house\n",
      "0 46.14874928013911 united\n",
      "0 43.640527431134 company\n",
      "0 43.55729329750984 official\n",
      "0 43.54189651887907 police\n",
      "0 42.19041080097914 city\n",
      "0 40.997242772580535 twitter\n",
      "0 40.94286730445308 woman\n",
      "0 39.80787257371681 united state\n",
      "0 39.70739393905273 say\n",
      "-----------------------------------------\n",
      "Important words in fake news articles\n",
      "1 89.85681039193022 hillary\n",
      "1 62.40370011846452 election\n",
      "1 53.896212310112716 email\n",
      "1 52.6133688150295 fbi\n",
      "1 51.0531903699768 2016\n",
      "1 47.95742854121367 hillary clinton\n",
      "1 47.246185697867105 war\n",
      "1 45.312378025328854 russia\n",
      "1 43.08880991275489 world\n",
      "1 36.950844723176125 campaign\n",
      "1 36.377542827884824 medium\n",
      "1 36.1397092607962 vote\n",
      "1 33.75617373039203 russian\n",
      "1 33.0982850696016 donald\n",
      "1 32.57668032187472 know\n"
     ]
    }
   ],
   "source": [
    "class_labels= NB.classes_\n",
    "feature_names =count_vectorizer.get_feature_names()\n",
    "topn_class1 = sorted(zip(NB.feature_count_[0], feature_names),reverse=True)[:30]\n",
    "topn_class2 = sorted(zip(NB.feature_count_[1], feature_names),reverse=True)[:30]\n",
    "print(\"Important words in real news articles\")\n",
    "\n",
    "for coef1, feat1 in topn_class1:\n",
    "    b = 0\n",
    "    for coef2, feat2 in topn_class2:\n",
    "        if feat1 ==feat2:\n",
    "            b = 1\n",
    "        else:\n",
    "            continue\n",
    "    if b ==0:\n",
    "        print(class_labels[0], coef1, feat1)\n",
    "    else:\n",
    "        continue\n",
    "            \n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Important words in fake news articles\")\n",
    "for coef2, feat2 in topn_class2:\n",
    "    b = 0\n",
    "    for coef1, feat1 in topn_class1:\n",
    "        if feat1 ==feat2:\n",
    "            b = 1\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    if b==0:\n",
    "        print(class_labels[1], coef2, feat2) \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85      2564\n",
      "          1       1.00      0.66      0.79      2636\n",
      "\n",
      "avg / total       0.87      0.83      0.82      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "predicted = NB.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2558    6]\n",
      " [ 893 1743]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7201923076923077\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
